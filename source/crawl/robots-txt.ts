// Given a hostname, retrieve its robots.txt file
// Maintain a pool of parsed robots.txt rules
// Expose a UrlFilter function that checks URLs against the robot rules
// Optionally return a sitemap
